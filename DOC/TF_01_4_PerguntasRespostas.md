# Tema 3 â€” SumarizaÃ§Ã£o de Texto com LLMs

## ğŸ¯ Objetivo EspecÃ­fico

Treinar e/ou aplicar modelos baseados em transformers para realizar **sumarizaÃ§Ã£o automÃ¡tica** de textos longos ou curtos em portuguÃªs, como notÃ­cias, artigos acadÃªmicos ou textos de redes sociais. A tarefa consiste em **gerar um resumo coerente e informativo**, preservando os pontos principais do conteÃºdo original.

---

## ğŸ“š SugestÃµes de Datasets PÃºblicos em PortuguÃªs

### 1. **CSTNews**
- **DescriÃ§Ã£o**: Corpus de textos jornalÃ­sticos em portuguÃªs, com resumos humanos anotados.
- **Fonte**: [https://github.com/linhd-postags/cstnews-corpus](https://github.com/linhd-postags/cstnews-corpus)
- **Tamanho**: Pequeno (~140 documentos), mas ideal para fine-tuning controlado.

### 2. **PUD_BR + Wikipedia Headlines**
- **DescriÃ§Ã£o**: Pode-se usar o cabeÃ§alho de notÃ­cias como resumo e o corpo como entrada.
- **ObservaÃ§Ã£o**: Requer prÃ©-processamento heurÃ­stico.

### 3. **CNN/Brazilian News Dataset (ExtraÃ§Ã£o Customizada)**
- **DescriÃ§Ã£o**: Pode ser criado com scraping de portais como G1, UOL, ou Globo, com tÃ­tulo como resumo e corpo como conteÃºdo.
- **Legalidade**: Apenas para uso educacional e experimental.

---

## ğŸ“¦ Requisitos Objetivos para o Projeto

1. Escolher ou criar um dataset com **pares (texto original, resumo)**
2. PrÃ©-processamento (remoÃ§Ã£o de HTML, truncamento de entrada se necessÃ¡rio)
3. Aplicar modelo prÃ©-treinado com ou sem fine-tuning
4. Avaliar com mÃ©tricas automÃ¡ticas de sumarizaÃ§Ã£o
5. Comparar o desempenho entre abordagens extractivas e abstrativas (se possÃ­vel)
6. Organizar o cÃ³digo em **notebook reprodutÃ­vel**
7. RelatÃ³rio final com anÃ¡lise qualitativa e quantitativa dos resumos gerados

---

## ğŸ“Š MÃ©tricas de AvaliaÃ§Ã£o

### 1. **ROUGE (Recall-Oriented Understudy for Gisting Evaluation)**
- **ROUGE-1**: sobre uni-gramas
- **ROUGE-2**: sobre bi-gramas
- **ROUGE-L**: sobre subsequÃªncia mais longa comum
- Quanto mais alto, melhor.

### 2. **BLEU (opcional)**
- Tradicionalmente usada em traduÃ§Ã£o, pode ser aplicada como comparaÃ§Ã£o n-gram entre resumo gerado e referÃªncia.

### 3. **AvaliaÃ§Ã£o Qualitativa (humana)**
- CoerÃªncia, concisÃ£o e fidelidade ao texto original.

---

## ğŸ“ SugestÃ£o de Roteiro TÃ©cnico

1. **Importar e analisar o dataset de sumarizaÃ§Ã£o**
2. **Tokenizar com modelo compatÃ­vel (T5, BART ou mT5)**
3. **Ajustar truncamento e padding (max_input_length, max_output_length)**
4. **Aplicar fine-tuning supervisionado** com `Trainer`
5. **Gerar resumos no conjunto de teste**
6. **Avaliar com `rouge_score` e/ou `evaluate` da Hugging Face**
7. **Mostrar exemplos comparando entrada, referÃªncia e saÃ­da gerada**

---

## ğŸ§  Modelos Recomendados

- `unicamp-dl/ptt5-base-portuguese-vocab` (T5 adaptado para portuguÃªs)
- `csebuetnlp/mT5_multilingual_XLSum` (mT5 treinado para sumarizaÃ§Ã£o multilÃ­ngue)
- `google/mt5-small` (prÃ©-treinado multilÃ­ngue)

---
