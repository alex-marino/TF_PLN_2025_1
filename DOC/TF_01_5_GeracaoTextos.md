# Tema 5 â€” GeraÃ§Ã£o de Texto com LLMs

## ğŸ¯ Objetivo EspecÃ­fico

Treinar e/ou aplicar modelos de linguagem de grande escala (LLMs) para realizar **geraÃ§Ã£o automÃ¡tica de texto** em portuguÃªs com base em instruÃ§Ãµes ou dados estruturados. A tarefa pode envolver:
- GeraÃ§Ã£o de **descriÃ§Ãµes de produtos**
- CriaÃ§Ã£o de **posts para redes sociais**
- ElaboraÃ§Ã£o de **resumos livres** a partir de tÃ³picos ou listas

A saÃ­da deve ser **coerente, relevante e linguÃ­stica e semanticamente adequada**.

---

## ğŸ“š SugestÃµes de Datasets PÃºblicos ou ConstruÃ§Ã£o PrÃ³pria

### 1. **BrWac + Wikipedia Topics**
- **DescriÃ§Ã£o**: Corpus extenso da web brasileira; pode-se extrair parÃ¡grafos e associar com tÃ­tulos como prompts.
- **Fonte**: [https://www.linguateca.pt/Repositorio/BrWaC/](https://www.linguateca.pt/Repositorio/BrWaC/)

### 2. **Amazon Reviews (DescriÃ§Ã£o + TÃ­tulo)**
- **DescriÃ§Ã£o**: Criar prompts com base no tÃ­tulo ou palavras-chave do produto e usar a descriÃ§Ã£o como target.

### 3. **Dataset prÃ³prio estruturado**
- **DescriÃ§Ã£o**: Criar planilha ou JSON com campos como `tÃ³pico` â†’ `texto desejado`.
- **Exemplo**:  
  - Entrada: `"tÃ³pico": "cadeira gamer"`  
  - SaÃ­da: `"descriÃ§Ã£o": "Cadeira ergonÃ´mica com apoio lombar e design esportivo."`

---

## ğŸ“¦ Requisitos Objetivos para o Projeto

1. Coletar ou montar dataset com **pares entrada â†’ texto-alvo**
2. Aplicar tokenizaÃ§Ã£o e ajuste de sequÃªncia para **modelos de geraÃ§Ã£o seq2seq**
3. Treinar modelo com `Trainer` ou usar `pipeline` para geraÃ§Ã£o direta
4. Avaliar resultados com mÃ©tricas automÃ¡ticas e anÃ¡lise qualitativa
5. Testar interatividade com novos prompts
6. Entregar notebook, relatÃ³rio e amostras de texto gerado

---

## ğŸ“Š MÃ©tricas de AvaliaÃ§Ã£o

### 1. **BLEU**
- Mede a similaridade entre o texto gerado e a referÃªncia, baseado em n-grams.

### 2. **ROUGE**
- Avalia a sobreposiÃ§Ã£o de conteÃºdo relevante (principalmente em resumos).

### 3. **Perplexidade (PPL)**
- Avalia a fluidez do modelo (quanto menor, melhor).

### 4. **AvaliaÃ§Ã£o qualitativa**
- Clareza, criatividade, adequaÃ§Ã£o ao prompt.

---

## ğŸ“ SugestÃ£o de Roteiro TÃ©cnico

1. **Carregar dataset com tÃ³picos ou prompts**
2. **Tokenizar com modelo de geraÃ§Ã£o (T5, GPT-2, mT5, etc.)**
3. **Ajustar `input_text` e `target_text`**
4. **Treinar com `AutoModelForSeq2SeqLM` ou `CausalLM`**
5. **Gerar novos textos a partir de instruÃ§Ãµes customizadas**
6. **Avaliar com mÃ©tricas BLEU, ROUGE e perplexidade**
7. **Analisar exemplos bons e ruins de saÃ­das geradas**

---

## ğŸ§  Modelos Recomendados

- `unicamp-dl/ptt5-base-portuguese-vocab` (T5 para portuguÃªs)
- `pierreguillou/t5-base-en-pt-small-train` (modelo traduzido/adaptado)
- `gpt2` ou `neuralmind/bert-base-portuguese-cased` (com ajustes)
- `tiiuae/falcon-rw-1b` (para tarefas de geraÃ§Ã£o zero-shot)

---

