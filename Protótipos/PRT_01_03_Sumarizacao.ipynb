{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# üß† Sumariza√ß√£o de Texto com LLMs ‚Äî Execu√ß√£o M√≠nima\n",
    "\n",
    "Este roteiro mostra como aplicar um modelo LLM pr√©-treinado para gerar resumos de textos em portugu√™s, usando a biblioteca ü§ó Hugging Face.\n",
    "\n",
    "---"
   ],
   "id": "7adf2b7bcdacdf9a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# üì• Carregar modelo T5 adaptado para portugu√™s",
   "id": "a792a7afe6ea8aea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Modelo adaptado para sumariza√ß√£o em portugu√™s\n",
    "modelo = \"unicamp-dl/ptt5-base-portuguese-vocab\"\n",
    "\n",
    "# Pipeline de sumariza√ß√£o\n",
    "sumarizador = pipeline(\"summarization\", model=modelo, tokenizer=modelo)\n"
   ],
   "id": "704199d253d0ac01"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# üìù Texto de entrada",
   "id": "ba572c1445a8f749"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "texto = (\n",
    "    \"O presidente da rep√∫blica discursou na abertura da confer√™ncia sobre mudan√ßas clim√°ticas \"\n",
    "    \"e afirmou que o Brasil ir√° cumprir as metas estabelecidas no Acordo de Paris. Ele destacou \"\n",
    "    \"a import√¢ncia da preserva√ß√£o da Amaz√¥nia e o compromisso com fontes renov√°veis de energia.\"\n",
    ")\n"
   ],
   "id": "3aef770fa4fcb58e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# üöÄ Gerar resumo",
   "id": "2a153b590c9e2bd8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "resumo = sumarizador(\n",
    "    texto,\n",
    "    max_length=80,\n",
    "    min_length=20,\n",
    "    do_sample=False\n",
    ")\n",
    "\n",
    "print(\"Resumo:\", resumo[0]['summary_text'])\n"
   ],
   "id": "f727309e386768f9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ‚úÖ Sa√≠da esperada\n",
    "\n",
    "\n",
    "Resumo: O presidente reafirmou o compromisso do Brasil com o Acordo de Paris e destacou a preserva√ß√£o da Amaz√¥nia.\n",
    "\n",
    "# üìå Observa√ß√µes\n",
    "Esse exemplo utiliza infer√™ncia direta com modelo pr√©-treinado (sem fine-tuning).\n",
    "\n",
    "O modelo ptt5-base foi treinado especificamente para tarefas em portugu√™s.\n",
    "\n",
    "Para textos mais longos, ajuste os par√¢metros max_length, min_length e ative truncation=True se necess√°rio.\n",
    "\n"
   ],
   "id": "a9b0b3eedadc5e07"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# üß† Fine-Tuning de Sumariza√ß√£o com T5 em Portugu√™s üáßüá∑\n",
    "\n",
    "Este roteiro mostra como realizar o fine-tuning de um modelo T5 adaptado para a l√≠ngua portuguesa, utilizando a biblioteca ü§ó Hugging Face Transformers e o dataset XLSum (vers√£o em portugu√™s).\n"
   ],
   "id": "6a356f50c6d50031"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# üìö Carregar dataset de exemplo",
   "id": "5b0c4fe4b37625fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Dataset multil√≠ngue com textos e resumos jornal√≠sticos\n",
    "dataset = load_dataset(\"csebuetnlp/xlsum\", \"portuguese\")\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "dataset[\"validation\"] = dataset[\"test\"]\n"
   ],
   "id": "99e61ab7b24dd056"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# üßπ Pr√©-processamento e tokeniza√ß√£o",
   "id": "b2149d61cef96cf8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"unicamp-dl/ptt5-base-portuguese-vocab\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "max_input_length = 512\n",
    "max_target_length = 128\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [\"sumarize: \" + doc for doc in examples[\"text\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"summary\"], max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n"
   ],
   "id": "f254a01f35fda828"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# üß† Carregar modelo T5 para sumariza√ß√£o",
   "id": "5ecf74e9f1c25e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n"
   ],
   "id": "d5dce247bcfc9efd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ‚öôÔ∏è Configura√ß√£o do treinamento",
   "id": "ad478a979a65d47c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True,\n",
    "    fp16=False  # Ativar se estiver usando GPU com suporte\n",
    ")\n"
   ],
   "id": "2c18f5a725c9ed3d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# üìä Avalia√ß√£o com ROUGE",
   "id": "8b7a394c9d025c0b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import evaluate\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    return rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n"
   ],
   "id": "e1f155d8fc1c729b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# üèãÔ∏è Treinar o modelo",
   "id": "2636ce6808495d9c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import Trainer, DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ],
   "id": "ee85d2fe805008d6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ‚úÖ Avalia√ß√£o final no conjunto de valida√ß√£o",
   "id": "59a56ef97bf25b11"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "trainer.evaluate()\n",
   "id": "102942bb20b4eccd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# üìå Observa√ß√µes\n",
    "O modelo unicamp-dl/ptt5-base-portuguese-vocab √© otimizado para tarefas como sumariza√ß√£o, tradu√ß√£o e gera√ß√£o de texto em portugu√™s.\n",
    "\n",
    "O dataset XLSum cont√©m pares (texto, resumo) para dezenas de idiomas, incluindo o portugu√™s.\n",
    "\n",
    "O par√¢metro predict_with_generate=True permite gerar sequ√™ncias durante a avalia√ß√£o, o que √© essencial para calcular ROUGE.\n",
    "\n"
   ],
   "id": "84f02690d5af28e3"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
