{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# üß† Gera√ß√£o de Texto com LLMs em Portugu√™s\n",
    "Exemplo com pipeline `text-generation` e fine-tuning m√≠nimo com base em t√≥picos.\n"
   ],
   "id": "d9b90439d48d3119"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ü§ñ Gera√ß√£o de texto com `pipeline` (modelo GPT-2 em portugu√™s)\n",
   "id": "fb1a5e2ba67372e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "gerador = pipeline(\"text-generation\", model=\"pierreguillou/gpt2-small-portuguese\")\n",
    "entrada = \"Descri√ß√£o de um notebook potente para programadores:\"\n",
    "saida = gerador(entrada, max_length=80, num_return_sequences=1)\n",
    "print(saida[0][\"generated_text\"])"
   ],
   "id": "59209415ac474d70"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## üìö Dataset de t√≥picos e textos curtos para fine-tuning",
   "id": "a7dbff5fe3b9867c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dados = {\n",
    "    \"entrada\": [\"cadeira gamer confort√°vel\", \"celular com boa c√¢mera e bateria\"],\n",
    "    \"texto\": [\n",
    "        \"Cadeira gamer com apoio lombar, encosto reclin√°vel e espuma de alta densidade.\",\n",
    "        \"Celular com c√¢mera de 108MP, bateria de longa dura√ß√£o e carregamento r√°pido.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "dataset = Dataset.from_dict(dados)\n",
    "dataset = dataset.train_test_split(test_size=0.5)"
   ],
   "id": "ce90db9da4a2984c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## üî§ Tokeniza√ß√£o com modelo T5 em portugu√™s",
   "id": "6c15a6f15078fe0d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "modelo = \"unicamp-dl/ptt5-base-portuguese-vocab\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelo)\n",
    "\n",
    "def preprocess(example):\n",
    "    input_text = [\"gerar: \" + x for x in example[\"entrada\"]]\n",
    "    model_inputs = tokenizer(input_text, padding=\"max_length\", truncation=True, max_length=128)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(example[\"texto\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess, batched=True)"
   ],
   "id": "1f77ca8732658eb4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## üß† Carregar modelo e configurar treinamento\n",
   "id": "4ef6bb3102fece90"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(modelo)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./modelo-gerador\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=2,\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=10,\n",
    "    predict_with_generate=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer, model)\n",
    ")\n",
    "\n",
    "trainer.train()"
   ],
   "id": "5111f7b3ceef0abb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ‚úÖ Gera√ß√£o de novos textos com modelo ajustado",
   "id": "1e00b2e82ae73abc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "entrada = \"gerar: fone bluetooth resistente √† √°gua e com cancelamento de ru√≠do\"\n",
    "tokens = tokenizer(entrada, return_tensors=\"pt\")\n",
    "output = model.generate(**tokens, max_new_tokens=60)\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))"
   ],
   "id": "aad94fae8aba98cd"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
